import undetected_chromedriver as uc
import time
import os
import glob
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from pathlib import Path
import logging
logging.basicConfig(filename='output.log', encoding='utf-8', level=logging.INFO)
logger = logging.getLogger(__name__)

chromeOptions = uc.ChromeOptions()
downloadFile_dir = 'D:\\work\\youDirector'
chromeOptions.add_experimental_option('prefs', {
    'download.default_directory' : downloadFile_dir,
    'download.prompt_for_download' : False,
    'download.directory_upgrade' : True,
    'plugins.always_open_pdf_externally' : True
})
chromeOptions.headless = True
driver = uc.Chrome(use_subprocess=True, options=chromeOptions)

current_page = 1

#check if download completed
def is_download_finished(temp_folder):
    chrome_temp_file = sorted(Path(temp_folder).glob('*.crdownload'))
    chrome_temp_file2 = sorted(Path(temp_folder).glob('*.tmp'))
    chrome_temp_file3 = sorted(Path(temp_folder).glob('*.md'))
    downloaded_files = sorted(Path(temp_folder).glob('*.*'))
    if (len(chrome_temp_file) == 0) and \
       (len(chrome_temp_file2) == 0) and \
       (len(chrome_temp_file3) == 0) and \
       (len(downloaded_files) >= 1):
        return True
    else:
        return False

#rename file after downloaded
def rename_last_downloaded_file(new_name):
    files  =glob.glob(os.path.join(downloadFile_dir, '*'))
    last_downloaded_file = max(files, key=os.path.getctime)
    file_extension = os.path.splitext(last_downloaded_file)[1]
    new_file_name = os.path.join(downloadFile_dir, new_name + file_extension)
    try:
        os.rename(last_downloaded_file, new_file_name)
        time.sleep(2)
        logger.info(f'rename from {last_downloaded_file} -> {new_file_name} ')
    except Exception as e:
            logger.info(e)
    return new_file_name

# Function to download a candidate's resume
def download_resume(candidate_urls):
    for key, value in candidate_urls.items():
        driver.get(value)
        time.sleep(2)
        # Find the download resume button and click it
        try:
            download_links = driver.find_elements(By.CSS_SELECTOR,"a.candidacy-profile-outline__file-link")
            for link in download_links:
                link.click()
                time.sleep(5)
                if is_download_finished(downloadFile_dir):
                    rename_last_downloaded_file(key + '_' +link.text)
                else:
                    time.sleep(2)

            #download interview rgs memo
            driver.get(value+"#files")
            time.sleep(2)
            download_memos = driver.find_elements(By.XPATH,"//div[@class='event-dragenter']")
            for memo in download_memos:
                memoSpan = memo.find_element(By.XPATH,".//span[@class='A_cuej6r6Yeu5OaYyWLT']")
                if memoSpan.text == 'その他':
                    memoLink = memo.find_elements(By.XPATH,".//a[@class='eAQLTDDUjSFnLSLcS9Lg']")
                    for link in memoLink:
                        link.click()
                        time.sleep(5)

            driver.back()
        except Exception as e:
            logger.info(e)
            driver.back()
            continue

driver.get("https://XXXXX/login")

uname = driver.find_element(By.NAME, "email")
uname.send_keys("yourEmail")
passwd = driver.find_element(By.NAME, "password")
passwd.send_keys("yourPassword")
driver.find_element(By.CSS_SELECTOR, "button").click()

driver.get(f"https://XXXXX/detail?page={current_page}")
time.sleep(2)

# Iterate through all pages and download resumes
while True:

    # Find the list of candidate links on the current page
    candidate_links = driver.find_elements(By.CSS_SELECTOR,"a.terminated-candidacies-table-list__profile-cell-text")
    logger.info(f'candidate_links len:{len(candidate_links)}')

    candidate_urls = {}
    # Download resumes for each candidate on the current page
    for link in candidate_links:
        candidate_urls[link.find_element(By.CSS_SELECTOR,"span.terminated-candidacies-table-list__name-box").text] = link.get_attribute("href")

    logger.info(candidate_urls)
    download_resume(candidate_urls)
    logger.info(f'page {current_page} Done!')

    # Check if there is a next page
    try:
        #force back to candidate page
        driver.get(f"https://XXXXX/detail?page={current_page}")
        time.sleep(2)
        next_button = driver.find_element(By.CSS_SELECTOR,"a.pagination__next")
        next_button.click()
        current_page += 1
        time.sleep(5)  # Wait for the next page to load
    except Exception as e:
        logger.info(e)
        break  # No more pages, exit the loop

# Close the browser
driver.close()
